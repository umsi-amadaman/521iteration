{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8dbb7b0711a5dee59fb9df955a5759cc",
          "grade": false,
          "grade_id": "cell-intro",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "kOqw0n6YbqM3"
      },
      "source": [
        "# Assignment 1\n",
        "# Statistics and Visualization (100 points)\n",
        "\n",
        "In this assignment, you'll explore a collection of datasets that demonstrate why visualization is crucial in data analysis and how relying solely on summary statistics can be misleading. You'll work with multiple files containing x-y coordinate data that share similar statistical properties but tell very different visual stories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f1624fa058a2f60d4b645dab9d2743f1",
          "grade": false,
          "grade_id": "cell-part1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "nHVPb0fkbqM8"
      },
      "source": [
        "## Part 1: Data Loading and Processing (15 points)\n",
        "\n",
        "In your working directory, you have several TSV (tab-separated values) files. It's common in data analysis to work with several related files with similar name stems. you can get a list of all files in your working directory using the os library. Run the cell below and take a look at the files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Get all files in current directory\n",
        "fileNames = os.listdir('.')\n",
        "fileNames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm_lMH2poITX",
        "outputId": "5713c50a-464a-4a6e-c401-4303b5571b99"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'mystery_data04.tsv',\n",
              " 'mystery_data07.tsv',\n",
              " 'mystery_data03.tsv',\n",
              " 'mystery_data12.tsv',\n",
              " 'mystery_data05.tsv',\n",
              " 'mystery_data10.tsv',\n",
              " 'mystery_data02.tsv',\n",
              " 'mystery_data09.tsv',\n",
              " 'mystery_data11.tsv',\n",
              " 'mystery_data06.tsv',\n",
              " 'mystery_data01.tsv',\n",
              " 'netflix_cleaned_data.csv',\n",
              " 'mystery_data13.tsv',\n",
              " 'mystery_data.tsv',\n",
              " 'mystery_data08.tsv',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to work with all the files that have names that begin with 'mystery' and are of the type '.tsv'. Note that all of those file names are strings in a list called fileNames. Lets use what we know about string methods and list comprehensions to filter just the fileNames we want.\n",
        "\n",
        "Hint: We can use list methods such as .startswith() and .endswith() in the following list comprehension"
      ],
      "metadata": {
        "id": "HLUEMfjioV1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fill in the blank to generate a list with just the desired fileNames\n",
        "mystery_fileNames = [fN for fN in fileNames if _____ and ________]\n",
        "mystery_fileNames"
      ],
      "metadata": {
        "id": "whc2KTEVo_JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, lets write a function that loads a TSV file and returns a pandas dataframe."
      ],
      "metadata": {
        "id": "HsrdX23BsreI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tsv_data(filename):\n",
        "    \"\"\"\n",
        "    Load a TSV file and return a pandas DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    filename : str\n",
        "        Name of TSV file to read\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    pandas.DataFrame\n",
        "        DataFrame containing data from TSV file\n",
        "\n",
        "    Example:\n",
        "    --------\n",
        "    >>> df = load_tsv_data('mystery_data1.tsv')\n",
        "\n",
        "    Example:\n",
        "    --------\n",
        "    >>> df = load_tsv_data('mystery_data1.tsv')\n",
        "    >>> print(df.head())\n",
        "       x      y\n",
        "    0  54.3  47.8\n",
        "    1  53.1  48.9\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "eIzS27jQsrM9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to use our function to load all the relevant datsets from the mystery_fileNames list.\n",
        "\n",
        "Note: In many real-world data science applications where the source file names contain\n",
        "important metadata or information, we would use a dictionary to maintain the connection\n",
        "between the data and its source file. For example:\n",
        "    datasets = {'sales_Minnesota': df1, 'sales_Michigan': df2}\n",
        "\n",
        "In contexts where the sequence matters, such as monthly or yearly datasets, or when you're doing batch processing, using a list data structure is preferred for ease of iteration.\n",
        "\n",
        "For this exercise, since we're just working with mystery datasets, we'll use a list\n",
        "for simpler iteration through our data.\n",
        "\n"
      ],
      "metadata": {
        "id": "Nw88k0v1u8zK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = []  # this empty list will hold all our DataFrames\n",
        "\n",
        "# Load each dataset into our list\n",
        "for filename in mystery_fileNames:\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "# Let's see what we loaded\n",
        "print(f\"Loaded {len(datasets)} datasets\")\n",
        "print(f\"Each dataset shape: {datasets[0].shape}\")  # checking first dataset's dimensions"
      ],
      "metadata": {
        "id": "eRkAvz71u8TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6ef1158018838ca8b5b728fce67e627e",
          "grade": false,
          "grade_id": "cell-part2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4uc7OHb2bqNB"
      },
      "source": [
        "## Part 2: Summary Statistics (30 points)\n",
        "\n",
        "Let's look at key statistical measures for each dataset including:\n",
        "- Mean and standard deviation for x and y coordinates\n",
        "- Correlation between x and y\n",
        "- Min and max values to understand the range of our data\n",
        "\n",
        "To do this create a list comprehension that calculates these statistics for each dataset.\n",
        "Hint: Each item in the list should be a dictionary containing the statistics for one dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5c8e9c4c6735e783c3f61dfdfd2dd9d6",
          "grade": false,
          "grade_id": "calculate_stats",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "u94RHModbqNC"
      },
      "outputs": [],
      "source": [
        "# Your code should create a list where each item is a dictionary of statistics for one dataset\n",
        "# Use enumerate(datasets) to number each dataset as dataset_1, dataset_2, etc.\n",
        "\n",
        "all_stats = [\n",
        "   # YOUR CODE HERE\n",
        "   raise NotImplementedError()\n",
        "]\n",
        "\n",
        "\"\"\"\n",
        "Expected output format:\n",
        "[\n",
        "   {\n",
        "       'dataset': 'dataset_1',\n",
        "       'mean_x': 54.266,\n",
        "       'mean_y': 47.835,\n",
        "       'std_x': 16.762,\n",
        "       'std_y': 26.935,\n",
        "       'correlation': -0.064,\n",
        "       'min_x': 15.34,\n",
        "       'max_x': 91.638,\n",
        "       'min_y': 0.0,\n",
        "       'max_y': 105.373\n",
        "   },\n",
        "   {\n",
        "       'dataset': 'dataset_2',\n",
        "       ...\n",
        "   },\n",
        "   ...\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "# Convert to DataFrame and round for cleaner display\n",
        "stats_df = pd.DataFrame(all_stats).round(3)\n",
        "\n",
        "# Display the results\n",
        "print(\"Summary Statistics for all datasets:\")\n",
        "display(stats_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "21019fdb4306652aa14cc5b6d5ca68fe",
          "grade": false,
          "grade_id": "cell-part3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "cAHFfompbqND"
      },
      "source": [
        "## Part 3: Written Analysis (10 points)\n",
        "\n",
        "Based on the summary statistics you calculated above:\n",
        "1. What type of relationship do you expect between x and y variables?\n",
        "\n",
        "2. What conclusions might you draw about this dataset based only on these statistics?\n",
        "\n",
        "3. What additional statistical measures might be helpful?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8678cb84a74a787332ed6ad5bafa4fd0",
          "grade": true,
          "grade_id": "written_analysis",
          "locked": false,
          "points": 20,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "wUR1WCBObqNE"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ee6487094030bbefc8f603f5b3caf323",
          "grade": false,
          "grade_id": "cell-part4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1OZoYLCnbqNF"
      },
      "source": [
        "## Part 4: Data Visualization (35 points)\n",
        "\n",
        "Now lets visualize all our datasets!\n",
        "We want to create a grid of scatter plots where:\n",
        "- Each dataset gets its own subplot which is a scatterplot of x vs y\n",
        "- All plots should have the same scale (hint: look at global min/max across all data)\n",
        "- Each subplot should include the dataset's statistics in a relevant textbox\n",
        "- The overall figure should be titled and well-labeled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c6335a26af49e0ba",
          "grade": false,
          "grade_id": "create_visualization",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "TevsvJ_NbqNG"
      },
      "outputs": [],
      "source": [
        "# First, let's determine our plot layout\n",
        "n_datasets = len(datasets)\n",
        "n_cols = 3  # you might want to adjust this\n",
        "n_rows = (n_datasets + n_cols - 1) // n_cols\n",
        "\n",
        "# YOUR CODE HERE: Create the figure and subplots\n",
        "raise NotImplementedError()\n",
        "\n",
        "\"\"\"\n",
        "Expected steps:\n",
        "1. Create figure and subplots with appropriate size\n",
        "2. Find global min/max values for consistent scaling\n",
        "3. For each dataset:\n",
        "   - Create scatter plot\n",
        "   - Add relevant statistics\n",
        "   - Set titles and labels\n",
        "4. Adjust layout and display\n",
        "\"\"\"\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c5c6ab65daf0e33a317b7cf0dc4b1806",
          "grade": false,
          "grade_id": "cell-extra-credit",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ALzif7ExbqNG"
      },
      "source": [
        "## Reflection (10 points)\n",
        "\n",
        "After completing your visualization:\n",
        "1. How do these visualizations compare to what you expected from the statistics?\n",
        "\n",
        "2. Why might it be important to use the same scale for all plots?\n",
        "\n",
        "3. What surprised you most about this exercise? What story do these visualizations tell that the statistics didn't?\n",
        "\n",
        "4. What are the implications for data analysis practices?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f1624fa058a2f60d4b645dab9d2743f1",
          "grade": true,
          "grade_id": "reflection",
          "locked": false,
          "points": 10,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "f9nQNm63bqNH"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "nbgrader": {
      "notebook_version": 2,
      "schema_version": 3
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}