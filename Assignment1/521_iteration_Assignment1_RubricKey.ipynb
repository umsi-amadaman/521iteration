{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "XIu7EtqWcKQN",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8dbb7b0711a5dee59fb9df955a5759cc",
     "grade": false,
     "grade_id": "cell-intro",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Datasaurus Assignment Solutions and Grading Guide\n",
    "\n",
    "This notebook contains solutions and grading guidelines for each part of the assignment. Total points: 100\n",
    "\n",
    "General grading philosophy:\n",
    "- Reward both correct functionality and good coding practices\n",
    "- Give partial credit for correct concepts even if implementation is flawed\n",
    "- Value insightful analysis even if technical execution isn't perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xw5aygoFcKQP",
    "outputId": "b9083fba-6eb9-4ac8-d7e9-b4d80e92ed7f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Get all files in current directory\n",
    "fileNames = os.listdir('.')\n",
    "fileNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "FsyfGqvZcKQQ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1624fa058a2f60d4b645dab9d2743f1",
     "grade": false,
     "grade_id": "cell-part1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 1: Data Loading and Processing (15 points)\n",
    "\n",
    "### List Comprehension Solution (5 points)\n",
    "\n",
    "Grading breakdown:\n",
    "- 2 points: Correct use of list comprehension syntax\n",
    "- 1.5 points: Correct use of startswith('mystery_data')\n",
    "- 1.5 points: Correct use of endswith('.tsv')\n",
    "\n",
    "Partial credit:\n",
    "- 2 points if using correct methods but with regular for loop\n",
    "- 1 point if filtering for only one condition correctly\n",
    "- 0.5 points for attempt with incorrect methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUcqGWBhdxka",
    "outputId": "63c7c1b0-62b5-4513-cdc7-1545d87bca2a"
   },
   "outputs": [],
   "source": [
    "mystery_fileNames = [fN for fN in fileNames if fN.startswith('mystery_data') and fN.endswith('.tsv')]\n",
    "mystery_fileNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHhnOU5-1HKs"
   },
   "source": [
    "### Loading Function Solution (5 points)\n",
    "\n",
    "Grading breakdown:\n",
    "- 3 points: Correct use of pd.read_csv()\n",
    "- 2 points: Correct specification of sep='\\t'\n",
    "\n",
    "Partial credit:\n",
    "- 2 points if they use read_csv without separator\n",
    "- 1 point if they attempt to read file but use wrong method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "QCe3oZHocKQQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3f6dd6f8c9546ca1f9203495c2df42b",
     "grade": false,
     "grade_id": "data_loading",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_tsv_data(filename):\n",
    "    \"\"\"Load a TSV file and return a pandas DataFrame.\"\"\"\n",
    "    return pd.read_csv(filename, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GZbnsuV1NER"
   },
   "source": [
    "### Loading Multiple Datasets Solution (5 points)\n",
    "\n",
    "Grading breakdown:\n",
    "- 2 points: Correct initialization of empty list\n",
    "- 3 points: Correct loading and appending in loop\n",
    "\n",
    "Partial credit:\n",
    "- 2 points if they load but don't store correctly\n",
    "- 1 point if they attempt iteration but don't load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P9ij9dWJ1Mz-",
    "outputId": "fc6b5576-e7ae-4155-b145-5bb47f12b82b"
   },
   "outputs": [],
   "source": [
    "datasets = []  # will hold all DataFrames\n",
    "\n",
    "for filename in mystery_fileNames:\n",
    "    df = load_tsv_data(filename)\n",
    "    datasets.append(df)\n",
    "\n",
    "print(f\"Loaded {len(datasets)} datasets\")\n",
    "print(f\"Each dataset shape: {datasets[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "U01XFndacKQR",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ef1158018838ca8b5b728fce67e627e",
     "grade": false,
     "grade_id": "cell-part2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 2: Summary Statistics (30 points)\n",
    "\n",
    "Grading breakdown:\n",
    "- 10 points: Correct list comprehension structure with enumerate\n",
    "- 5 points: Correct calculation of means\n",
    "- 5 points: Correct calculation of standard deviations\n",
    "- 5 points: Correct calculation of correlation\n",
    "- 5 points: Correct calculation of min/max values\n",
    "\n",
    "Partial credit:\n",
    "- 15 points if using for loop instead of list comprehension\n",
    "- -2 points for each missing statistic\n",
    "- 5 points if structure is correct but calculations are wrong\n",
    "- 10 points if calculations are correct but structure is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "deletable": false,
    "id": "uc7YGI8HcKQR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c8e9c4c6735e783c3f61dfdfd2dd9d6",
     "grade": false,
     "grade_id": "statistics",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "f96da6ce-c137-4e1e-ef8d-f15c5bbfc88d"
   },
   "outputs": [],
   "source": [
    "all_stats = [\n",
    "    {'dataset': f'dataset_{i+1}',\n",
    "\n",
    "        'mean_x': df['x'].mean(),\n",
    "        'mean_y': df['y'].mean(),\n",
    "        'std_x': df['x'].std(),\n",
    "        'std_y': df['y'].std(),\n",
    "        'correlation': df['x'].corr(df['y']),\n",
    "        'min_x': df['x'].min(),\n",
    "        'max_x': df['x'].max(),\n",
    "        'min_y': df['y'].min(),\n",
    "        'max_y': df['y'].max()\n",
    "    }\n",
    "    for i, df in enumerate(datasets)\n",
    "]\n",
    "\n",
    "stats_df = pd.DataFrame(all_stats).round(3)\n",
    "display(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Ejf21113cKQS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21019fdb4306652aa14cc5b6d5ca68fe",
     "grade": false,
     "grade_id": "cell-part3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 3: Written Analysis (20 points)\n",
    "\n",
    "Based on the summary statistics you calculated above:\n",
    "1. What type of relationship do you expect between x and y variables?\n",
    "2. Sketch what you think the data might look like when plotted.\n",
    "3. What conclusions might you draw about this dataset based only on these statistics?\n",
    "4. What additional statistical measures might be helpful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "7fWVWgeJcKQS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1624fa058a2f60d4b645dab9d2743f1",
     "grade": true,
     "grade_id": "written_analysis",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "\n",
    "**Example of full-credit response:**\n",
    "1. Based on the near-zero correlations (around -0.06), we would expect little to no linear relationship between x and y variables. The data might appear as a random cloud of points.\n",
    "\n",
    "2. The similar means, standard deviations, and ranges across all datasets suggest these are very similar or possibly identical datasets. The x values consistently center around 54 with std dev ~17, while y values center around 48 with std dev ~27.\n",
    "\n",
    "3. Additional helpful measures might include:\n",
    "   - Quartiles or percentiles to understand distribution shape\n",
    "   - Tests for normality\n",
    "   - Non-linear correlation measures\n",
    "   - Measures of modality\n",
    "\n",
    "**Grading breakdown:**\n",
    "- 4 points: Correct interpretation of correlation\n",
    "- 3 points: Recognition of similarity across datasets\n",
    "- 3 points: Thoughtful suggestions for additional measures\n",
    "\n",
    "**Partial credit:**\n",
    "- Deduct 1-2 points for shallow analysis\n",
    "- Minimum 2 points for any reasonable attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "-ozzCB4fcKQS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee6487094030bbefc8f603f5b3caf323",
     "grade": false,
     "grade_id": "cell-part4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 4: Data Visualization (35 points)\n",
    "\n",
    "Grading breakdown:\n",
    "- 5 points: Correct layout calculation\n",
    "- 5 points: Proper figure sizing\n",
    "- 5 points: Global min/max calculation\n",
    "- 10 points: Correct subplot creation and iteration\n",
    "- 5 points: Adding statistics to plots\n",
    "- 5 points: Consistent scaling across plots\n",
    "\n",
    "Partial credit:\n",
    "- -5 points if scales aren't consistent\n",
    "- -5 points if statistics are missing\n",
    "- -3 points if grid/labels are missing\n",
    "- Half credit if plots are created but poorly formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "deletable": false,
    "id": "68BnzYO0cKQT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6335a26af49e0ba",
     "grade": false,
     "grade_id": "visualization",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "db0bc07c-a7eb-4219-a7a8-377c9145c1a0"
   },
   "outputs": [],
   "source": [
    "# Calculate layout\n",
    "n_datasets = len(datasets)\n",
    "n_cols = 3\n",
    "n_rows = (n_datasets + n_cols - 1) // n_cols\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(15, 5 * n_rows))\n",
    "\n",
    "# Calculate global min/max\n",
    "all_x = pd.concat([df['x'] for df in datasets])\n",
    "all_y = pd.concat([df['y'] for df in datasets])\n",
    "x_min, x_max = all_x.min(), all_x.max()\n",
    "y_min, y_max = all_y.min(), all_y.max()\n",
    "\n",
    "# Create subplots\n",
    "for i, df in enumerate(datasets, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "\n",
    "    # Create scatter plot\n",
    "    plt.scatter(df['x'], df['y'], alpha=0.5)\n",
    "\n",
    "    # Add statistics text box\n",
    "    stats = stats_df.iloc[i-1]\n",
    "    stats_text = f\"μx={stats['mean_x']:.1f}\\n\"\n",
    "    stats_text += f\"μy={stats['mean_y']:.1f}\\n\"\n",
    "    stats_text += f\"ρ={stats['correlation']:.2f}\"\n",
    "\n",
    "    plt.text(0.05, 0.95, stats_text,\n",
    "             transform=plt.gca().transAxes,\n",
    "             bbox=dict(facecolor='white', alpha=0.8),\n",
    "             verticalalignment='top')\n",
    "\n",
    "    # Set consistent scales\n",
    "    plt.xlim(x_min - 1, x_max + 1)\n",
    "    plt.ylim(y_min - 1, y_max + 1)\n",
    "\n",
    "    plt.title(f'Dataset {i}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "o1ZNOiXxcKQT",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c5c6ab65daf0e33a317b7cf0dc4b1806",
     "grade": false,
     "grade_id": "cell-reflection",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Reflection (10 points)\n",
    "\n",
    "**Example of full-credit response:**\n",
    "\n",
    "1. The visualizations reveal that despite having nearly identical summary statistics, each dataset forms a completely different pattern. This is a striking demonstration of why visualization is crucial in data analysis.\n",
    "\n",
    "2. Consistent scaling is essential here because:\n",
    "   - It allows direct comparison between datasets\n",
    "   - It prevents misleading interpretations\n",
    "   - It reveals the true relative sizes of patterns\n",
    "\n",
    "3. The most surprising aspect is how such different patterns can share the same summary statistics. This demonstrates that summary statistics alone can hide important patterns in data.\n",
    "\n",
    "4. Implications for data analysis:\n",
    "   - Always visualize data before drawing conclusions\n",
    "   - Don't rely solely on summary statistics\n",
    "   - Consider multiple approaches to understanding data\n",
    "   - Be aware that different visualization techniques might reveal different patterns\n",
    "\n",
    "**Grading breakdown:**\n",
    "- 3 points: Recognition of the disconnect between statistics and visualization\n",
    "- 3 points: Understanding of scaling importance\n",
    "- 4 points: Thoughtful reflection on implications\n",
    "\n",
    "**Partial credit:**\n",
    "- Half credit for surface-level observations without deeper insight\n",
    "- -2 points if missing any major point\n",
    "- Full credit requires specific examples or insights"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nbgrader": {
   "notebook_version": 2,
   "schema_version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
